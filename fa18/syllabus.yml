# - unit: <N>
#   name: "<unit-title>"
#   list:
#     - name: "<full-lecture-title>"
#       file: "<url-for-website>" # looks like... /<group>/<semester>/<file>
#       covr: "<url-to-image>" # this will be added to the banner for each meeting
#       inst: [<instructor_1>, <instructor_2>, ...]
#       date: "<MM>/<DD>"
#       desc: > # the ">" specifies to YAML its a multi-line string
#         <meeting-description>

meet_day: "Wed"
meet_time: "4:30pm"
meet_room: "PSY 105"

signup_url: "https://docs.google.com/forms/d/e/1FAIpQLSdZ5ZZ49gUaDD2LbvRMuRgx3_AscFTWHpWDDuQOISTC1MnwIg/viewform"
signin_url: "https://docs.google.com/forms/d/e/1FAIpQLSdZ5ZZ49gUaDD2LbvRMuRgx3_AscFTWHpWDDuQOISTC1MnwIg/viewform"

teach:
- unit: 0
  name: "Basics"
  list:
    - name: "Welcome back! Featuring Plotting & Supercomputers"
      file: "welcome-back"
      covr: "https://www.autodesk.com/products/eagle/blog/wp-content/uploads/2018/04/shutterstock_1011096853.jpg"
      inst: [ionlights, Waldmannly]
      date: "08/29"
      desc: >
        Welcome back to SIGAI! We'll be re-introducing SIGAI for newcomers and
        refreshing it for veterans. Following that, we'll cover some basics of
        generating graphs (a very common task for data science and research). If
        you're enticed, we'll also get you setup on the university's
        supercomputer, as all following meetings will stream from there! :smiley:
    - name: "Intro to Data Analysis with Pandas & Numpy"
      file: "learn-numpy-pandas"
      covr: "https://www.cfertech.com/sites/cfertech.com/files/nodefiles/822/RLX_Data_Analysis_banner.jpg"
      inst: [ionlights]
      date: "09/12"
      desc: >
        Data is arguably more important than the algorithms we'll be learning
        this semester - and that data almost always needs to be curated and
        finagled to really develop an understanding of what the data is trying
        to tell you.
    - name: "Let Data Speak Using Regression & Plots"
      file: "linear-regression"
      covr: "http://www.sthda.com/english/sthda-upload/figures/machine-learning-essentials/027-logistic-regression-probabilities-curve-1.png"
      inst: [ahl98]
      date: "09/19"
      desc: >
        Neural Networks are all the rage, nowadays, but simpler models are
        always great places to start! We'll cover how to do Linear/Logistic
        Regression as well as preparing data for such a function to work.
- unit: 1
  name: "neural-nets"
  list:
    - name: "Flowering your Pokémon Predictions, with Neural Networks"
      file: "neural-nets"
      inst: [ionlights, ChasKane]
      covr: ""
      date: "09/26"
      desc: >
        With some basic ideas in mind about how one might tackle a task, we'll
        now go and explore a Tensor framework (PyTorch) and build a Neural
        Network that can accurately predict XXXX from our dataset.
    - name: "Convolutional Neural Networks"
      file: "conv-nets"
      covr: ""
      inst: [thedibaccle]
      date: "10/03"
      desc: >

    - name: "Machines That Write Papers for You"
      file: "recurrent-nets"
      covr: ""
      inst: [ionlights]
      date: "10/10"
      desc: >

    - name: "Who Made this Face?"
      file: "gans"
      covr: ""
      inst: [thedibaccle]
      date: "10/17"
      desc: >

- unit: 2
  name: "alt-methods"
  list:
    - name: "Solving the Computationally Impossible with Heuristics"
      file: "heuristics"
      covr: "https://nomaneveati.files.wordpress.com/2015/06/bird_example.png?w=518&h=233&zoom=2"
      inst: [Waldmannly]
      date: "10/24"
      desc: >
 The world is complex, making it difficult for algorithms to come to solutions in reasonable amounts of time. To speed them along, we can employ Heuristics to get us significantly closer, faster.  Today, we’ll try to approximate the Traveling Salesman Problem by using Simulated Annealing and Particle Swarm Optimization – two Heuristics which move us towards finding the shortest path we can use to visit all the destinations.

    - name: "Decision Trees"
      file: "decision-trees"
      covr: "http://dataaspirant.com/wp-content/uploads/2017/01/B03905_05_01-compressor.png"
      inst: [ChasKane]
      date: "10/31"
      desc: >
        Sometimes the algorithms we use to predict the future can be difficult to interpret and trust.
        A Decision Tree is a learning algorithm that does a half decent job at prediction, but, more importantly,
        is very easy to understand and interpret. No black boxes here... untill we start talking about Random Forests ;)

    - name: "Support Vector Machines"
      file: "svms"
      covr: ""
      inst: [ahl98]
      date: "11/07"
      desc: >

- unit: 3
  name: "implementation"
  list:
    - name: "Practice Makes Permanent, but Data's Messy"
      file: "practice-data-cleaning"
      covr: ""
      inst: [ionlights]
      date: "11/14"
      desc: >
        
