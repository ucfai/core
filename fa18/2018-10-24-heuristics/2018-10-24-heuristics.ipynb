{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "signup-banner"
   },
   "source": [
    "<img style=\"border-radius: 0.5rem;\" src=\"banner.jpg\" />\n",
    "<a style=\"margin-top: 1rem;\" class=\"btn btn-lg btn-block btn-success\" href=\"https://dsg.ucfsigai.org/fa18/signin/\">\n",
    "    Sign in (https://dsg.ucfsigai.org/fa18/signin/)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "Solving the Computationally Impossible with Heuristics",
    "type": "sigai_heading"
   },
   "source": [
    "# Solving the Computationally Impossible with Heuristics\n",
    "---\n",
    "by: Evan Waldmann \\([@Waldmannly](github.com/Waldmannly/)\\), on 10 Oct 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization techniques usually rely on have a nice, continuous function that is capable of being minimized through derivative based techniques such as gradient descent. \n",
    "\n",
    "So, say we wanted to minimize a simple function like f(x) = x^4 + x^2 -4 x^2 + 10. Optimization methods basically do what you used to do when you took calculus. You find d/dx(f(x)) solve for x and plug the answer back into f(x). \n",
    "\n",
    "So d/dx(f(x)) = 4x^3 + 2x - 8 x = x^2 (4x - 6). Then we have \n",
    "\n",
    "x^2 =0 and 4x-6 = 0. So our x is 0 and +- sqrt(3/2). \n",
    "\n",
    "then we plug in f(x) and get (0,10), (-3/2, 31/4), (3/2, 31/4). So we technically have two global minima. \n",
    "\n",
    "\n",
    "\n",
    "But what do we do for real world problems that can not be boiled down to a nice differentible function? \n",
    "\n",
    "Well, we end up guessing, which works when we don't care if we have the exact solution (i.e. the absolute minimum). \n",
    "\n",
    "If the problem if simple enough, we usually just test all of the possible scenarios and take the best value as our answer. Since computes are super fast, this often works well because its easy. \n",
    "\n",
    "BUT when the problems are not simple, we have to make our computers make smarter guesses. \n",
    "\n",
    "Let's look at a classic problem called the Traveling Salesman Problem that has been around since the 1930's. \n",
    "\n",
    "\n",
    "TALK ABOUT TSP problem \n",
    "\n",
    "\n",
    "If you were to brute force by randomly guessing then running time would end up being O(n!), so for any number of cities over say 20 it would be unrealistic. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So what are some ideas that you have for making your computer guess a bit smarter. (Those of you done with CS1 or CS2 should have a few ideas). \n",
    "\n",
    "\n",
    "Well most of those answers can be boiled down to either \n",
    " (1) Exploration  - looking around the solution space to gather more information\n",
    " (2) Exploitation - Making the best descision given the current information \n",
    " \n",
    "I am not going to dive too deep into the the theory here, because it does get dense and statistically hard very quickly. The idea is that we need to explore in order to make sure that we did not miss anything that could be hiding in the solution space, but we also need to exploit what we know so that we can get as close as we can to the right solution. The problem is that these to idea are competing with each other, often if we are exploring we can not exploit and if we are exploiting we can not explore. The balance of these two ideas is pretty much what the field of heuristics is all about (and the \"correct\" answer often depends on the solution you are trying to solve).  \n",
    " \n",
    " \n",
    " \n",
    "So the key take away is that  heuristics is about smart guessing and by either exploring the solution space or exploiting what we know, we can help our computer guess a bit better.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "type": "dataloader"
   },
   "outputs": [],
   "source": [
    "def dataset(path):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    datadir = Path(os.environ[\"DATA_DIR\"])\n",
    "    return Path(datadir.joinpath(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important things in heuristics is how you encode your problem into your code. \n",
    "It is important to recognize that almost every solution will be encoded differently, so you can think of these heuristic algorithms as a framework that you can shape to fit your problem. \n",
    "\n",
    "For the traveling sales man problem our solution will be a \"tour\" of cites. We will represent this as a vector of numbers [2 4 3 1 6 5], where this vector will mean that our tour travels from 2 to 4 to 3 and so on. \n",
    "\n",
    "Since the problem is about finding the minmum distance to tour all of the cities, we need a cost function that calculates the distance for a given vector. \n",
    "\n",
    "We also need to figure out how to guess solutions that should be close to some given solution. This make our guessing less random. \n",
    "\n",
    "With that we can define the traveling sales man random neighboring solution generator and solution cost function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[2 3 5 1 0 4 6]\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def tspobjective(a, d):\n",
    "    ofv = 0\n",
    "    for i in range(len(a)-1):\n",
    "        ofv = ofv + d[a[i]][a[i+1]]\n",
    "    ofv = ofv +  d[a[len(a)-1]][a[1]]  \n",
    "    return ofv;\n",
    "\n",
    "a = [4 ,2 ,6 ,1 ,7 ,5 ,3]\n",
    "d = [[0,   6, 42, 29,  5, 13, 25, 44, 44,  8],[6 ,  0, 44, 44, 22, 37,  7, 19, 42, 36 ],[42 ,44,  0, 44, 30,  2, 39, 43, 31, 35 ], [29, 44 ,44,  0 ,34, 18 ,30,  8, 32,  2 ],[ 5, 22 ,30, 34 , 0 ,13 , 3 , 5, 38, 32 ], [13, 37  ,2, 18 ,13 , 0 ,15 ,43,  2, 20 ],[25,  7 ,39, 30 , 3 ,15 , 0 ,18, 35, 36 ],[44, 19 ,43,  8  ,5 ,43 ,18 , 0,  9, 23 ],[44, 42 ,31, 32 ,38 , 2 ,35 , 9,  0, 21 ], [8, 36, 35 , 2, 32 ,20, 36 ,23, 21,  0 ]]\n",
    "\n",
    "\n",
    "print(tspobjective(a,d))\n",
    "\n",
    "\n",
    "randomperm = np.random.permutation(7)\n",
    "print(randomperm)\n",
    "print(tspobjective(randomperm,d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "[3 4 1 0 2 5 6]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.permutation(7)\n",
    "ofv = tspobjective(a,d)\n",
    "bestofv = ofv\n",
    "bestTour = a \n",
    "\n",
    "for j in range(10):\n",
    "    a = np.random.permutation(7)\n",
    "    ofv = tspobjective(a,d)\n",
    "    if (ofv < bestofv):\n",
    "        bestofv = ofv \n",
    "        bestTour = a \n",
    "    \n",
    "print(bestofv)\n",
    "print(bestTour)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 6, 1, 7, 5, 3]\n",
      "[4, 2, 6, 1, 3, 5, 7]\n",
      "[4, 1, 6, 2, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def tspswap(a):\n",
    "    l = random.randint(0,len(a)-1)\n",
    "    m = random.randint(0,len(a)-1)\n",
    "    while l==m:\n",
    "        m = random.randint(0,len(a)-1)\n",
    "    temp = a[l]\n",
    "    a[l] = a[m]\n",
    "    a[m] = temp\n",
    "    newa = a\n",
    "    return(newa); \n",
    "\n",
    "a = [4 ,2 ,6 ,1 ,7 ,5 ,3]\n",
    "print(a)\n",
    "print(tspswap(a))\n",
    "print(tspswap(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 0 3 1 6 4]\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "a = np.random.permutation(7)\n",
    "bestofv = tspobjective(a,d)\n",
    "best=a[:]\n",
    "\n",
    "for i in range(1,10):  \n",
    "    #generate neighbor sols\n",
    "    na= tspswap(a)\n",
    "    naofv = tspobjective(na,d)\n",
    "    if (naofv<bestofv):\n",
    "        best = na[:]\n",
    "        bestofv = naofv\n",
    "    a = na[:] #create neighbors from the neighbor to get variety \n",
    "    \n",
    "Best = best \n",
    "BestOFV = bestofv \n",
    "\n",
    "print(Best)\n",
    "print(bestofv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4 2 6 1 7 5 3]\n",
    "d = [[0   6 42 29  5 13 25 44 44  8 ]\n",
    "     [6   0 44 44 22 37  7 19 42 36 ]\n",
    "     [42 44  0 44 30  2 39 43 31 35 ]\n",
    "     [29 44 44  0 34 18 30  8 32  2 ]\n",
    "     [ 5 22 30 34  0 13  3  5 38 32 ]\n",
    "     [13 37  2 18 13  0 15 43  2 20 ]\n",
    "     [25  7 39 30  3 15  0 18 35 36 ]\n",
    "     [44 19 43  8  5 43 18  0  9 23 ]\n",
    "     [44 42 31 32 38  2 35  9  0 21 ]\n",
    "      [8 36 35  2 32 20 36 23 21  0 ]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristics are usually based off of processes in nature and the first algorithm I am going to cover is called Simulated Annealing.\n",
    "\n",
    "The idea for simulated Annealing came from the process of hardening metal. In order to harden metal you heat it up and left it cool -- its called annealing. \n",
    "\n",
    "So how exactly does that relate to smart guessing? \n",
    "\n",
    "Well when you heat up the metal to when it is glowing read, the particles in the metal are bouncing around a lot, and as the metal slowly cools, the particles start to move less and less. This gives us a frame work for how to guide our exploration versus exploitation. When the metal is super hot, we are going to explore the solution space more, and as we cool, we are going settle in on specific spots in the space that have produced good results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2, 5, 4, 6, 1, 3], 87, 574, 74, [120, 120, 120, 120, 120, 120, 120, 120, 120, 118, 118, 118, 118, 106, 106, 106, 106, 106, 106, 98, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import math \n",
    "\n",
    "def SA(a,d, T,tf, N, K, alpha):\n",
    "    currenta = a[:]\n",
    "    besta = a[:]\n",
    "    bestofv = tspobjective(a,d)\n",
    "    ofvNew = bestofv\n",
    "    ofvOld = bestofv\n",
    "    na =currenta[:]\n",
    "    #initalize counting variables \n",
    "    n=1\n",
    "    k=1\n",
    "    kk=0\n",
    "    iteration =-1\n",
    "    x= [0 for x in range(100)]\n",
    "    #outer loop\n",
    "    while tf<T:\n",
    "        iteration = iteration +1\n",
    "        #reset counting variables\n",
    "        n=1\n",
    "        k=1\n",
    "        #inner loop\n",
    "        while n<= N and k<=K:\n",
    "            #generate neighbor solution \n",
    "            na= tspswap(currenta[:])[:]\n",
    "            kk = kk+1 #summation of total number of solution generated \n",
    "            #store values so you only have to compute them once\n",
    "            ofvNew = tspobjective(na, d)\n",
    "            ofvOld = tspobjective(currenta,d)\n",
    "            if (ofvNew < ofvOld): #check to see if neighbor solution is better \n",
    "                currenta = na[:]\n",
    "                n=n+1\n",
    "                k=k+1\n",
    "                if ofvNew < bestofv: #check if neighbor solution is best \n",
    "                    bestofv = ofvNew\n",
    "                    besta = currenta[:]\n",
    "            elif random.uniform(0, 1) < math.exp(-(ofvNew -ofvOld)/T):#check to accept bad solution\n",
    "                k=k+1\n",
    "                n=n+1\n",
    "                currenta= na[:]\n",
    "            else:\n",
    "                n=n+1\n",
    "        T= alpha*T #decrease Temperature \n",
    "        x[iteration] = bestofv\n",
    "    return(besta, bestofv, kk,iteration,x); \n",
    "    \n",
    "N=20\n",
    "K=5 #stopping condition for inside loop\n",
    "T=10000\n",
    "tf =4 #stopping condition for outer loop \n",
    "alpha = .9 #rate of cooling \n",
    "a = [1,2,3,4,5,6]\n",
    "print(SA(a, d, T, tf, N,K,alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will finish up this lecture by cover Particle Swarm Optimization (PSO). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4, 0, 5, 2, 3, 6, 1]), array([0, 1, 3, 5, 6, 4, 2]), array([6, 5, 4, 1, 2, 3, 0]), array([2, 1, 6, 5, 4, 3, 0])]\n",
      "[107, 160, 180, 148]\n",
      "[4 0 5 2 3 6 1]\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "#Set algorithm parameters (Num_particles, Max_time _step, w, c 1 , c 2 ).tstep=1.\n",
    "import math \n",
    "num_particles= 4\n",
    "max_time_step = 5\n",
    "w = 2 # number of chances to have a neighbor solution to the particles current solution\n",
    "c1 = 2# number of chances to have a neighbor solution to the particles best solution\n",
    "c2 = 1 # number of chances to have a neighbor solution to the global best solution \n",
    "tstep = 1\n",
    "numcites =7\n",
    "\n",
    "#Generate initial particles.\n",
    "particles = [np.random.permutation(numcites) for particles in range(num_particles)]\n",
    "ofvs = [-1 for ofvs in range(num_particles)]\n",
    "for i in range(0,num_particles):\n",
    "    ofvs[i] = tspobjective(particles[i],d)\n",
    "\n",
    "\n",
    "print(particles)\n",
    "print(ofvs)\n",
    "\n",
    "#set up variables for tracking particle and global bests \n",
    "globalbestofv = min(ofvs)\n",
    "globalbest = particles[ofvs.index(min(ofvs))]\n",
    "print(globalbest)\n",
    "print(globalbestofv)\n",
    "particlesbest = particles[:]\n",
    "particlesbestofv = ofvs[:]\n",
    "\n",
    "# run the PSO algorithm \n",
    "while tstep<= max_time_step:\n",
    "    #• For each particle\n",
    "    for p in range(0,num_particles-1):\n",
    "        #• Construct a chance box\n",
    "        x = [-1 for x in range(numcites)]\n",
    "        chanceBox = [ x for chanceBox in range(w+c1+c2)]\n",
    "        #• Generate w neighbour solutions from selected particle and put them in the chance box.\n",
    "        for i in range(0,w): \n",
    "            chanceBox[i] = tspswap(particles[p])\n",
    "        #• Generate c 1 neighbour solutions from corresponding particle’s pbest and put them in the chance box.\n",
    "        for i in range(w,w+c1): \n",
    "            chanceBox[i] = tspswap(particlesbest[p])\n",
    "        # Generate c 2 neighbour solutions from the gbest and put them in the chance box.\n",
    "        for i in range(w+c1, w+c1+c2):\n",
    "            chanceBox[i] = tspswap(globalbest)\n",
    "        # Select a solution from the chance box randomly\n",
    "        particles[p] = chanceBox[random.randint(0,w+c1+c2-1)]#• Consider the selected solution as the new position of the selected particle\n",
    "        #• Calculate the objective function value of all particles\n",
    "        ofvs[p] = tspobjective(particles[p] ,d)\n",
    "        #update pbest if needed\n",
    "        if (ofvs[p] < particlesbestofv[p]):\n",
    "            particlesbestofv[p] = ofvs[p]\n",
    "            particlesbest[p] = particles[p] \n",
    "    #update gbest if needed \n",
    "    globalbestofvTemp = min(ofvs)\n",
    "    if (globalbestofvTemp < globalbestofv):\n",
    "        globalbest = particles[ofvs.index(min(ofvs))]\n",
    "        globalbestofv = globalbestofvTemp\n",
    "    tstep =tstep+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 3 6 0 1 5]\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "print(globalbest)\n",
    "print(globalbestofv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "sigai": {
   "authors": [
    {
     "github": "Waldmannly",
     "name": "Evan Waldmann"
    }
   ],
   "date": "2018-10-24",
   "description": "",
   "title": "Solving the Computationally Impossible with Heuristics",
   "unit": {
    "name": "alt-methods",
    "number": 2
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
