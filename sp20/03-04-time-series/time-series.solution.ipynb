{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "nb-title",
     "template"
    ],
    "title": "Time Series Analysis"
   },
   "source": [
    "<img src=\"https://ucfai.org/core/sp20/time-series/banner.png\">\n",
    "\n",
    "<div class=\"col-12\">\n",
    "    <h1> Time Series Analysis </h1>\n",
    "    <hr>\n",
    "</div>\n",
    "\n",
    "<div style=\"line-height: 2em;\">\n",
    "    <p>by: \n",
    "        <a href=\"https://ucfai.org/authors/nspeer12\">@nspeer12</a>\n",
    "        \n",
    "         on Mar 04, 2020</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "tags": [
     "template"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/kaggle/input\")\n",
    "if (DATA_DIR / \"ucfai-core-sp20-time-series\").exists():\n",
    "    DATA_DIR /= \"ucfai-core-sp20-time-series\"\n",
    "else:\n",
    "    # You'll need to download the data from Kaggle and place it in the `data/`\n",
    "    #   directory beside this notebook.\n",
    "    # The data should be here: https://kaggle.com/c/ucfai-core-sp20-time-series/data\n",
    "    DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Data\n",
    "### Looking to the past to infer  the future\n",
    "\n",
    "Time series data is a special kind of data that we will be exploring in this notebook. Time series data has a few important properties such as:\n",
    "- it's sequential\n",
    "- time is the independent variable\n",
    "- observed at discrete intervals, such as 5 minutes or 1 hour\n",
    "\n",
    "Let's dive into some examples of time series data and learn how we can observe, understand, and predict this unique kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# matplotlib configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Time Series Data\n",
    "Time series data consists of data points recorded at discrete intervals over time. This kind of data occurs everywhere in our lives, a few examples include:\n",
    "- Stock market data\n",
    "- Ocean tides\n",
    "- Commute times\n",
    "- Weather and outdoor temperatures\n",
    "- Business sales or revenue\n",
    "- Disney World line wait times    \n",
    "And so many more examples. Time series data is so common, it becomes increasingly important to learn how to analyze it. In this notebook, we'll be taking on the challenge of using the past to predict the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dow Jones Industrial Average\n",
    "Abbreviated as DJI and commonly refered to as the \"Dow\", this financial index monitors the prices of 30 large US companies such as Apple, Home Depot, IBM and Disney. The Dow is a good indicator of how the US stock markets are performing overall. The Dow dates back to 1885 and was founded by a Wall Street Journal reporter, Charles Dow, and his statitician, Edward Jones. We're going to take a look at the Dow and use it as an example to learn some important properties of time series data.\n",
    "\n",
    "## Columns\n",
    "- Date\n",
    "    Our data dates back to 1985. It includes every day the stock market open, which is normal week days. This excludes weekends and holidays.\n",
    "- Open\n",
    "    The price our data opens 9:30 AM New York Time.\n",
    "- High\n",
    "    The highest price the Dow reaches during the day.\n",
    "- Low\n",
    "    The lowest price of the Dow during each day\n",
    "- Close\n",
    "    The price of the Dow when the market closes at 4:00 New York Time.\n",
    "- Adj Close\n",
    "    The closing price adjusted for dividends and stock splits.\n",
    "- Volume\n",
    "    The number of transactions on the market during each day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for Dow Jones Index\n",
    "df = pd.read_csv(DATA_DIR / 'DJI.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(df['Open'], color='green', label='Dow Jones Opening Price')\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xlabel('Days')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last 100 days of Dow opening prices with date labels\n",
    "fig, axs = plt.subplots(2, figsize=(20,10))\n",
    "\n",
    "# To plot dates is a somewhat expensive operation, so we're only going to look at the past m days\n",
    "m = 100\n",
    "dow = df[:m]\n",
    "\n",
    "# plot the Dow with dates on the first axes\n",
    "axs[0].plot(dow['Date'], dow['Open'], color='green', label='Dow Jones Opening Price')\n",
    "axs[0].set_ylabel('Price')\n",
    "axs[0].set_xlabel('Days')\n",
    "\n",
    "# plot volume using a bar graph on the second axes\n",
    "axs[1].bar(dow['Date'], dow['Volume'], color='blue', alpha=0.5, label='Dow Jones Volume')\n",
    "\n",
    "# show every nth x tick label\n",
    "i = 5\n",
    "plt.xticks([x for x in dow['Date']][::i])\n",
    "\n",
    "\n",
    "# rotate date labels\n",
    "fig.autofmt_xdate()\n",
    "axs[0].format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "axs[1].format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "\n",
    "# show legend\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Averages\n",
    "The first analysis tool that we'll be looking at is called a moving average. We're going to be looking at a subset of our data across a given range, and then be taking the average of all of the observations within that range. To do this, we'll loop through our entire dataset, then loop through each sliding window and calculate the average of that window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 5 day moving average\n",
    "MA5 = []\n",
    "\n",
    "# start at the fifth index and loop through all data\n",
    "for i in range(5, len(df)):\n",
    "    # sum previous 5 data points and average them\n",
    "    sum = 0\n",
    "    for j in range(i-5, i):\n",
    "        sum += df['Adj Close'][j]\n",
    "    # add the average to the list\n",
    "    MA5.append(sum / 5)\n",
    "    \n",
    "\n",
    "# drop rows 0 - 5\n",
    "df = df[:-5]\n",
    "\n",
    "# append the moving average to the data frame\n",
    "df['MA5'] = MA5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the 5 day moving average we just calculated\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "# zoom in a bit\n",
    "plt.axis([2300, 2500, 3600, 4000])\n",
    "ax.plot(df['Open'], color='blue', label='Dow Jones Open')\n",
    "ax.plot(df['MA5'], color=\"green\", label='5 Day MA')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of averages to calculate\n",
    "averages = [10, 15, 50, 100, 200, 500]\n",
    "\n",
    "# expand our data to several different moving averages\n",
    "for avg in averages:\n",
    "    # easier way to calculate moving averages than using for loop method\n",
    "    df['MA' + str(avg)] = df['Adj Close'].rolling(window=avg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the new moving averages in our data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values, which is up to our largest moving average\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "# adjust the view\n",
    "plt.axis([5000, 8000, 5000, 20000])\n",
    "\n",
    "ax.plot(df['Adj Close'], c='green', label='Dow Adj Close')\n",
    "\n",
    "for avg in averages:\n",
    "    name = 'MA' + str(avg)\n",
    "    ax.plot(df[name], label=name)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Moving Averages\n",
    "Exponential moving averages work similarly to simple moving averages, except they add greater weight to more recent values. This is a good way to see what our trends look like with some \"memory\" of the past, while still being reactive to recent trends and sudden movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWM: Exponential Weighted Functions\n",
    "\n",
    "df['EMA5'] = df['Open'].ewm(span=5, adjust=False).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.axis([6100, 6200, 7500, 10000])\n",
    "\n",
    "ax.plot(df['Open'], c='green', label='Dow Open')\n",
    "ax.plot(df['EMA5'], c='blue', label='5 Day EMA')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare EMA to SMA\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.axis([6100, 6200, 7500, 10000])\n",
    "ax.plot(df['Open'], c='green', label='Dow Open')\n",
    "ax.plot(df['EMA5'], c='blue', label='5 Day EMA')\n",
    "ax.plot(df['MA5'], c='orange', label='5 Day SMA')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposing Data\n",
    "For any given time series data set, there are a lot of factors that go into each value. For the stock market, some of it is seemingly random, yet many top traders are able to extract useful information in order to better their odds. Decomposing data is the method of extracting each working piece of time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition\n",
    "\n",
    "### Additive formula: y(t) = S(t) + T(t) + R(t)\n",
    "#### y = seaonality + trend + remainder\n",
    "\n",
    "### Multiplicative formula: y(t) = S(t) * T(t) * R(t)\n",
    "#### y = seaonality * trend * remainder\n",
    "\n",
    "### Seasonality\n",
    "Imagine data being subjected to cyclical forces, like tides of the ocean or seasons of the year\n",
    "\n",
    "#### Examples\n",
    "- In most locations, the temperature is going to cooler in winter in warmer in summer\n",
    "- TSA wait times are going to be longer during holiday seasons.\n",
    "- Historically stocks perform the worst in september.\n",
    "\n",
    "### Trend\n",
    "What sort of momentum does the data have?\n",
    "\n",
    "#### Examples\n",
    "- Moore's Law\n",
    "- Increasing global population\n",
    "- Global poverty decreasing\n",
    "\n",
    "### Remainder\n",
    "Randomness, noise\n",
    "\n",
    "#### Examples\n",
    "- microsecond flucuations in the price of the stock\n",
    "- seemingly random warm day in winter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Travel Passenger Dataset\n",
    "This data set shows the number of monthly airline travelers from 1949 to 1960. Maybe you are one of the many people that have experienced the long wait times and crowded planes during the holidays. The data shows this huge uptick that occurs during each year, seemingly like clockwork. We're going to be applying seasonal decomposition to this dataset and learn how we can find each of the working pieces of this time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR / 'AirPassengers.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(df['Month'], df['Passengers'], color='blue', label='Passenger Volume')\n",
    "\n",
    "# fancy way to show every nth tick label\n",
    "n = 12\n",
    "plt.xticks([x for x in df['Month']][::n])\n",
    "    \n",
    "fig.autofmt_xdate()\n",
    "ax.format_xdata = mdates.DateFormatter('%Y')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detrending Data\n",
    "Many factors influence the measurements we observe in time series data. For instance, in the 20th century, air travel was an emergent industry that saw a steady increase. We can estimate this general trend of growth and then subtract it from each point to greater understand the other trends that have influence. Once we detrend our data, we can isolate and observe the seasonality in our data.\n",
    "\n",
    "### Setting a Base Line\n",
    "This step is going to be highly dependent on the data set being detrended. In most cases that show a generally increasing or decreasing trend, there will be a sort of \"Goldilocks\" value that will work well. Try to establish some sort of baseline that is around the low end of the data and covers most of the are underneath the data. In this example, we'll be using a 48 month moving average that creates a nice baseline to our data.\n",
    "\n",
    "#### Why 48?\n",
    "We're using a 48 month moving average because it is a multiple of 12. Since we are looking at seasonality, we want to be left with perfect 12 month periods.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 48 Month moving average as the trend line\n",
    "# note: we're using 48 here for a couple reasons\n",
    " \n",
    "df['MA48'] = df['Passengers'].rolling(window=48).mean()\n",
    "\n",
    "# plot the the trend line\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(df['Month'], df['Passengers'], color='blue', label='Passenger Data')\n",
    "ax.plot(df['MA48'], color='green', label='48 Month MA')\n",
    "\n",
    "n = 6\n",
    "plt.xticks([x for x in df['Month']][::n])\n",
    "fig.autofmt_xdate()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use some algebra\n",
    "### S(t) + R(t) = y(t) - T(t)\n",
    "By subtracting our trend line from our seasonal data, we'll be left with our seasonal data, plus some randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the trend line from the passenger data\n",
    "df['detrend'] = df['Passengers'] - df['MA48']\n",
    "\n",
    "# plot detrended data\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(df['detrend'], color='orange', label='detrended data')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Seasonal Fluctuation')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Seasonality\n",
    "In the graph above, it's obvious that our data follows a cyclical pattern. In this next bit of code, what we're going to do is overlay each year on top of each other to show the recurrent pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold our annual detrended data\n",
    "annual = pd.DataFrame()\n",
    "\n",
    "# iterate and chop our data into 12 month periods\n",
    "i = 0\n",
    "while (i * 12) < (len(df['detrend']) - 12):\n",
    "    x = i * 12\n",
    "    annual[i] = df['detrend'].iloc[x:x+12].reset_index(drop=True)\n",
    "    i += 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "fig.suptitle('Annual Seasonal Data')\n",
    "for i in range(0, 11):\n",
    "    ax.plot(annual[i], label='year '+str(i))\n",
    "\n",
    "\n",
    "# plot each month out on a timeline\n",
    "ax.set_xlabel('Month')\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "plt.xticks(ticks=[x for x in range(12)], labels=months)\n",
    "ax.set_ylabel('Seasonal Fluctuation')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Mean\n",
    "To identify what our seasonal fluctuation looks like on average, we'll be taking the average of each year. Doing this will allow us to estimate what our seasonal difference may look like in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average seasonal data by taking the mean from each year\n",
    "annual['Seasonal Mean'] = annual.mean(axis=1)\n",
    "# blue line represents seasonal trend\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "for i in range(0, 11):\n",
    "    ax.plot(annual[i], label='year '+ str(i), alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_title('Detrended Seasonal Data')\n",
    "ax.plot(annual['Seasonal Mean'], color='blue', label='Seasonal Mean')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Seasonal Fluctuation')\n",
    "ax.set_xlabel('Month')\n",
    "plt.xticks(ticks=[x for x in range(12)], labels=months)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicative Formula\n",
    "In the cell below, we're going to implement a multiplicative formula using the statsmodels seasonal decomposition library. This library will expidite a lot of the previous work we just did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented with statsmodels\n",
    "# not as much fun, but a whole lot easier\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# strips time\n",
    "def parser(x):\n",
    "    return datetime.datetime.strptime(x, '%Y-%m')\n",
    "\n",
    "data = pd.read_csv(DATA_DIR / 'AirPassengers.csv', delimiter=',', index_col=['Month'], parse_dates=True, squeeze=True, date_parser=parser)\n",
    "\n",
    "# try toggling the model between additive and multiplicative!\n",
    "res = seasonal_decompose(data, model='multiplicative')\n",
    "pd.plotting.register_matplotlib_converters() # this fixes an error when plotting\n",
    "res.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "ARIMA stands for Autoregressive Integrated Moving Average\n",
    "\n",
    "### AR: Autoregression\n",
    "Model that uses the dependent relationship between an observation and some number of lagged observations.\n",
    "\n",
    "### I: Integrated\n",
    "Integrated meaning the decomposition of data using differencing, or subtracting previous values from each other, to make the data stationary.\n",
    "\n",
    "### MA: Moving Average\n",
    "Average of previous time series observations over a given period.\n",
    "\n",
    "Each of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.\n",
    "\n",
    "The parameters of the ARIMA model are defined as follows:\n",
    "\n",
    "#### p: The number of lag observations included in the model, also called the lag order.\n",
    "#### d: The number of times that the raw observations are differenced, also called the degree of differencing.\n",
    "#### q: The size of the moving average window, also called the order of moving average.\n",
    "\n",
    "source, and for more information on ARIMA: https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation\n",
    "Autocorrelation is the similarity between observed time series observations. By analyzing autocorrelation, we can try to pick up signals such as seasonality and fluctuation.\n",
    "By plotting autocorrelation, we can see which time lag window has the highest correlation. When we make the ARIMA model, we want to pick a lag observation window that has a high correlation. We can adjust this window using our \"p\" parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# plot autocorrelation\n",
    "autocorrelation_plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA With Regression\n",
    "Let's take a look at an ARIMA model that uses regression on the lag to fit to our training.\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate values\n",
    "X = df['Passengers'].values\n",
    "\n",
    "# manual test-train split\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# create a new list for our training data. We'll expand this list once we \"see\" testing values\n",
    "history = [x for x in train]\n",
    "\n",
    "# list to store just our predictions\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions at each point in our testing data\n",
    "for t in range(len(test)):\n",
    "    # since our training data is dynamically growing, we make and train a new model each iteration\n",
    "    model = ARIMA(history, order=(5,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    \n",
    "    # make a prediction\n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    # forecast method returns a tuple, take the first value\n",
    "    yhat = output[0]\n",
    "    \n",
    "    # add prediction to our list\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # add our testing value back into our history\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    \n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(test, color='blue', label='test data')\n",
    "ax.plot(predictions, color='red', label='predictions')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet Model\n",
    "\n",
    "### Seasonal Decomposition + Holidays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "print(df)\n",
    "# create a copy of the data frame and rename columns so they work nicely with fbprophet library\n",
    "df = df.rename(columns={'Month':'ds', 'Passengers': 'y'})\n",
    "\n",
    "# fit the model to our data frame\n",
    "model.fit(df)\n",
    "\n",
    "# make a new dataframe for the forecast\n",
    "future = model.make_future_dataframe(periods=12, freq='M')\n",
    "\n",
    "# make a forecast\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# plot forecast\n",
    "fig = model.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corona Virus Dataset\n",
    "The 2019 Novel Coronavirus is a global pandemic that is spreading quickly throughout the world. You are tasked with analyzing and forcasting the spread of this virus. Use your data science and CS skills to help fight the outbreak!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data set below, it's totally not in the right format that we want\n",
    "df = pd.read_csv(DATA_DIR / 'covid_19_data.csv', delimiter=',')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: sum up confirmed cases and plot a graph over time\n",
    "\n",
    "# create a dictionary (hash map) to store the total observations on a given date\n",
    "keys = [date for date in df['ObservationDate'].unique()]\n",
    "casesMap = dict.fromkeys(keys, 0)\n",
    "\n",
    "# iterate through each row and add up the number of confirmed cases to a hash map\n",
    "# TODO: Sum up the total confirmed cases in the hash map\n",
    "for index, row in df.iterrows():\n",
    "    ### BEGIN SOLUTION\n",
    "    date = row['ObservationDate']\n",
    "    casesMap[date] += row['Confirmed']\n",
    "    ### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have each of the totals in a dict object, now we have to put them back into time series data\n",
    "\n",
    "# create a new dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# add in a row for each of our dates\n",
    "df['Date'] = keys\n",
    "print(df.head())\n",
    "\n",
    "# add in a new row for confirmed cases at each date\n",
    "df['Confirmed'] = [casesMap[x] for x in keys]\n",
    "df = df.dropna()\n",
    "\n",
    "print('\\n Confirmed Cases Dataframe')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the number of confirmed cases over time\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(df['Date'], df['Confirmed'], label='Confirmed Cases', color='red')\n",
    "fig.autofmt_xdate()\n",
    "ax.fmt_xdata = mdates.DateFormatter('%m/%d/%Y')\n",
    "ax.legend();\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the 5 Day Moving Average and plot it\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# calculate moving average\n",
    "df['MA5'] = df['Confirmed'].rolling(window=5).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(df['Date'], df['Confirmed'])\n",
    "ax.plot(df['Date'], df['MA5'])\n",
    "fig.autofmt_xdate()\n",
    "ax.fmt_xdata = mdates.DateFormatter('%m/%d/%Y')\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply linear regression to the graph\n",
    "model = Prophet()\n",
    "    \n",
    "# create a copy of the data frame and rename columns so they work nicely with fbprophet\n",
    "df = df.rename(columns={'Date':'ds', 'Confirmed': 'y'})\n",
    "\n",
    "model.fit(df)\n",
    "future = model.make_future_dataframe(periods=60)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# changing format of the dates\n",
    "forecast['ds'] = [x.strftime('%m/%d/%Y') for x in forecast['ds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "# plot lower and upper bound of forecast and compare to real data\n",
    "dates = [d for d in forecast['ds']]\n",
    "ax.plot(df['ds'], df['y'], color='green', label='Real Confirmed Cases')\n",
    "ax.plot(dates, forecast['yhat_lower'], color='blue', label='yhat lower')\n",
    "ax.plot(dates, forecast['yhat_upper'], color='orange', label='yhat upper')\n",
    "\n",
    "# fancy way to show every nth tick label\n",
    "n = 7\n",
    "plt.xticks([x for x in forecast['ds']][::n])\n",
    "    \n",
    "fig.autofmt_xdate()\n",
    "ax.format_xdata = mdates.DateFormatter('%m-%d-%Y')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the ARIMA model to forecast the spread of Coronavirus\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# Make predictions at each point in our testing data\n",
    "# Isolate values\n",
    "X = df['y'].values\n",
    "\n",
    "# manual test-train split\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# create a new list for our training data. We'll expand this list once we \"see\" testing values\n",
    "history = [x for x in train]\n",
    "\n",
    "# list to store just our predictions\n",
    "predictions = []\n",
    "\n",
    "for t in range(len(test)):\n",
    "    # since our training data is dynamically growing, we make and train a new model each iteration\n",
    "    model = ARIMA(history, order=(1,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    \n",
    "    # make a prediction\n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    # forecast method returns a tuple, take the first value\n",
    "    yhat = output[0]\n",
    "    \n",
    "    # add prediction to our list\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # add our testing value back into our history\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    \n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(test, color='blue', label='test data')\n",
    "ax.plot(predictions, color='red', label='predictions')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to forecast 30 days into the future\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "forecast = model_fit.forecast(steps=30)[0]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(forecast, label='ARIMA Coronavirus Forecast')\n",
    "ax.set_xlabel('Days into the Future')\n",
    "ax.set_ylabel('Estimated Confirmed Cases')\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Show the increase of confirmed cases by location over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autobot": {
   "abstract": "How can we infer on the past to predict the future? In this meeting we are going to be learning about time series data and its unique qualities. After we sharpen up our data science skills, we will be putting them to good use by analyzing and predicting the spread of the Coronavirus!",
   "authors": [
    "nspeer12"
   ],
   "date": "2020-03-04T17:30:00",
   "group": "core",
   "semester": "sp20",
   "tags": [
    "Time Series",
    "Temporal Predictions"
   ],
   "title": "Time Series Analysis"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
