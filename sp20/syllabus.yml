- !Meeting
  required:
    id: 8f863b4f2ad5d2600cb549cf885be1065f9423efbd7526a3f3e73457fab26bb7
    date: !Timestamp 2020-01-22 17:30:00
    title: Starting with the Basics, Regression
    authors: [JarvisEQ, bb912]
    filename: regression
    cover-image: https://pbs.twimg.com/media/Dqb-Nk_XcAAm1_j.jpg
    tags: [regression, linear regression, logistic regression]
    room: HPA1 112
    abstract: >-
      You always start with the basics, and with AI it's no different! We'll be
      getting our feet wet with some simple, but powerful, models and
      demonstrate their power by applying them to real world data.
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 1oDo8_RpLqBdq5BcE-mWFGkKAsxY5cns5FN19hZDl42s
      youtube: 0vCF6S3mfQ
    kaggle:
      enable_gpu: false
- !Meeting
  required:
    id: f4e062e38f3af1c13d1bdd69d4316f7f887c276cccd3b6e262382c49dd4b9263
    date: !Timestamp 2020-01-29 17:30:00
    title: A Walk Through the Random Forest
    authors: [JarvisEQ, nspeer12]
    filename: rf-svm
    cover-image: https://upload.wikimedia.org/wikipedia/commons/1/17/Tarvasj%C3%B5gi.jpg
    tags: [Random Forests, SVMs, Nearest Neighbors]
    room: HPA1 112
    abstract: >-
      In this lecture, we explore powerful yet lightweight models that are often
      overlooked. We will see the power of combining multiple simple models
      together and how they can yield amazing results. You won't believe how
      easy it is to classify with just a line!
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 1hoICW_Y9b85H5P2OVMZyUs-vsMPnsF0sTIzb-11auqM
      youtube: sIKNRSSYPX
    kaggle:
      enable_gpu: false
- !Meeting
  required:
    id: 6dc27ebdfd28b038c01891fea481029ae06bced5aae1c42b91c96609e98a8263
    date: !Timestamp 2020-02-05 17:30:00
    title: Introduction to Neural Networks
    authors: [JarvisEQ, DillonNotDylan]
    filename: neural-nets
    cover-image: https://cdn-images-1.medium.com/max/1200/1*4V4OU2GEzmOWHgCJ8varUQ.jpeg
    tags: [Neural Networks, Gradient Descent, Backpropagation, Deep Learning]
    room: HPA1 112
    abstract: >-
      You've heard about them: Beating humans at all types of games, driving cars,
      and recommending your next Netflix series to watch, but what ARE neural networks?
      In this lecture, you'll actually learn step by step how neural networks function
      and learn. Then, you'll deploy one yourself!
    use-notebooks: true
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 17Kw1gwzo5YmXbHdHac-j8TnpIt4Re76u7uzjhfEEmQA
      youtube: -3-nasQMyEk
    kaggle:
      enable_gpu: true
- !Meeting
  required:
    id: f29fd30d995b70644cc34d151e5547f7da5c92fd1c1fb501ffd9fdfc4f0e3c04
    date: !Timestamp 2020-02-12 17:30:00
    title: How We Can Give Our Computers Eyes and Ears
    authors: [danielzgsilva]
    filename: conv-nets
    cover-image: ttps://cdn-5b4e2f92f911c85e6c496f87.closte.com/wp-content/uploads/2018/10/computer_vision-400x208.png
    tags: [Convolutional Networks, Image Processing, Feature Extraction]
    room: HPA1 112
    abstract: >-
      Ever wonder how Facebook tells you which friends to tag in your photos, or
      how Siri can even understand your request? In this meeting we'll dive into
      convolutional neural networks and give you all the tools to build smart
      systems such as these. Join us in learning how we can grant our computers
      the gifts of hearing and sight!
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 1BpYClnt2HdEceNSfzKN8ULbN6r8q8a0MFSrZu58alVk
      youtube: 2IEF1iSqTVY
    kaggle:
      enable_gpu: trueu
- !Meeting
  required:
    id: 02bd0d1ba8b748d9358b7d92e4026786f78890833071c2067ae912aa2a3d00fe
    date: !Timestamp 2020-02-19 17:30:00
    title: Writer's Block? RNNs Can Help!
    authors: [brandons209, DillonNotDylan, ionlights]
    filename: recurrent-nets
    cover-image: https://i.imgur.com/EIt4Ilr.png
    tags: [Recurrent Networks, Natural Language Processing, Text Generation]
    room: HPA1 112
    abstract: >-
      This lecture is all about Recurrent Neural Networks. These are networks
      with memory, which means they can learn from sequential data such as
      speech, text, videos, and more. Different types of RNNs and strategies
      for building them will also be covered. The project will be building a
      LSTM-RNN to generate new original scripts for the TV series "The
      Simpsons". Come and find out if our networks can become better writers
      for the show!
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 1fFRGIzIBP_cSpv2NiP3map1vWn-FXjaTfircPauG3WE
      youtube: lGizWY2w_Aw
    kaggle:
      enable_gpu: true
- !Meeting
  required:
    id: 1367f61cfe397e862d1c2465bdf4cbea5298c37c980328a36c43556e356119b7
    date: !Timestamp 2020-02-26 17:30:00
    title: Machine Learning Applications
    authors: [brandons209, nspeer12]
    filename: ml-apps
    cover-image: https://www.cubix.co/wp-content/uploads/2017/11/Guide-to-Machine-Learning-and-AI.jpg
    tags: [Applications, Pokémon, Pokédex, Expolanets, Machine Learning]
    room: HPA1 112
    abstract: >-
      It's time to put what you have learned into action. Here, we have prepared
      some datasets for you to build a a model to solve. This is different from
      past meetings, as it will be a full workshop. We provide the data sets and
      a notebook that gets you started, but it is up to you to build a model to
      solve the problem. So, what will you be doing? We have two datasets, one
      is using planetary data to predict if a planet is an exoplanet or not, so
      your model can help us find more Earth-like planets that could contain
      life! The second dataset will be used to build a model that mimics a
      pokedex! Well, not fully, but the goal is to predict the name of a pokemon
      and also predict its type (such as electric, fire, etc.) This will be
      extremely fun and give you a chance to apply what you have learned, with
      us here to help!
  optional:  # All `optional` keys are enumerated in the Documentation
    kaggle:
      enable_gpu: true
- !Meeting
  required:
    id: 3e589fcdc955f69df131662e4428e5ba2a97cd1e6c2efe62037de2ee3b950bca
    date: !Timestamp 2020-03-04 17:30:00
    title: Time Series Analysis
    authors: [nspeer12]
    filename: time-series
    cover-image: https://s31888.pcdn.co/wp-content/uploads/2018/07/index.jpg
    tags: [Time Series, Temporal Predictions, Coronavirus]
    room: HPA1 112
    abstract: >-
      How can we infer on the past to predict the future? In this meeting
      we are going to be learning about time series data and its unique
      qualities. After we sharpen up our data science skills, we will be
      putting them to good use by analyzing and predicting the spread of the
      Coronavirus!
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 16Gp1QBEB9faVjxICC4Cpi8dZ-TTE1FZjr0gBjZ8Y_cU
    kaggle:
      enable_gpu: false
    papers: {}
- !Meeting
  required:
    id: b914b7d0fd34cbfcf7807e5aaa89c8275cb76b66d879e223d684f26635a44f7e
    date: !Timestamp 2020-03-18 17:30:00
    title: A Look Behind DeepFake ~ GANs
    authors: [brandons209, bb912]
    filename: gans
    cover-image: https://i1.wp.com/cyxu.tv/wp-content/uploads/2019/03/horse2zebra.jpg
    tags: [DeepFake, GANs, CycleGANs, generative models]
    room: HPA1 112
    abstract: >-
      GANs are relativity new in the machine learning world, but they have
      proven to be a very powerful architecture. Recently, they made headlines
      in the DeepFake network, being able to mimic someone else in real time in
      both video and audio. There has also been cycleGAN, which takes one domain
      (horses) and makes it look like something similar (zebras). Come and learn
      the secret behind these type of networks, you will be surprised how
      intuitive it is! The lecture will cover the basics of GANs and different
      types, with the workshop covering how we can generate human faces, cats,
      dogs, and other cute creatures!
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: 1kgO5dgnWDM-3oJTVSJeOwY8u__bWC7lvQUxCPAbpSfE
      youtube: CvOFuN-NnM0
    kaggle:
      enable_gpu: true
- !Meeting
  required:
    id: cebdadd4fdcde94eb6eea2edcbe663d4df6d06f8ef91ca2c1bd3afb1ff4318cb
    date: !Timestamp 2020-04-01 17:30:00
    title: Training Machines to Learn From Experience
    authors: [danielzgsilva, JarvisEQ, ionlights]
    filename: reinforcement-learning
    cover-image: https://nulltx.com/wp-content/uploads/2018/10/robot-maze.jpg
    tags: [Reinforcement Learning, Q-learning, OpenAI Gym]
    room: HPA1 112
    abstract: >-
      We all remember when DeepMind’s AlphaGo beat Lee Sedol, but what actually
      made the program powerful enough to outperform an international champion?
      In this lecture, we’ll dive into the mechanics of reinforcement learning
      and its applications.
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides: ''
      youtube: ''
    kaggle:
      competitions: false
- !Meeting
  required:
    id: 43c316921632d149a2e626c58f8ad5e4fd4aec01bef6970954cddd72f0235c3e
    date: !Timestamp 2020-04-08 17:30:00
    title: Building AI, the Human Way
    authors: [ionlights]
    filename: build-ai-the-human-way
    cover-image: https://neuroscape.ucsf.edu/wp-content/uploads/glassbrain-gazzaleylab-neuroscapelab-18-1024x542.jpg"
    tags: [common sense ai, intuitive theories, probabilistic programming, program
        induction, cognitive science, machine learning, computational cognitive science,
      intuitive psychology, intuitive physics, inverse graphics]
    room: MSB 359
    abstract: >-
      We've learned about linear and statistical models as well as different
      training paradigms, but we've yet to think about how it all began. In
      Cognitive Computational Neuroscience, we look at AI and ML from the
      perspective of using them as tools to learn about human cognition, in
      the hopes of building better AI systems, but more importantly, in the
      hopes of better understanding ourselves.
    use-notebooks: false
  optional:  # All `optional` keys are enumerated in the Documentation
    urls:
      slides:
    kaggle: false
    papers:
      how-to-grow-a-mind: https://pdfs.semanticscholar.org/e7e4/bc08c9c746fda4721ac9e2206b4472e44b85.pdf
      machines-learn-think-people: https://arxiv.org/pdf/1604.00289.pdf
      machines-learn-think-themselves: https://arxiv.org/pdf/1711.08378.p
